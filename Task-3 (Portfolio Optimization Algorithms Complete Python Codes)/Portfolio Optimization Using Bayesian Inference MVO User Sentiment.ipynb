{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmEH098mDZJU",
        "outputId": "d452ead3-317e-4bd2-d905-4dcc86645d77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:yfinance:Could not get exchangeTimezoneName for ticker 'UPL.NS' reason: 'chart'\n",
            "[*********************100%***********************]  48 of 48 completed\n",
            "ERROR:yfinance:\n",
            "1 Failed download:\n",
            "ERROR:yfinance:['UPL.NS']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py:11211: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  base_cov = np.cov(mat.T, ddof=ddof)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "[*******************   40%                       ]  2 of 5 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 Stocks Based on Risk-Return Optimization:\n",
            "RELIANCE.NS: 0.0208\n",
            "TCS.NS: 0.0208\n",
            "HDFCBANK.NS: 0.0208\n",
            "INFY.NS: 0.0208\n",
            "ICICIBANK.NS: 0.0208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n",
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NaN values in train_data: Ticker\n",
            "HDFCBANK.NS     0\n",
            "ICICIBANK.NS    0\n",
            "INFY.NS         0\n",
            "RELIANCE.NS     0\n",
            "TCS.NS          0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pymc as pm\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "\n",
        "nifty_50_tickers = [\n",
        "   'RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS',\n",
        "    'KOTAKBANK.NS', 'BHARTIARTL.NS', 'AXISBANK.NS', 'ITC.NS', 'LT.NS',\n",
        "   'NTPC.NS', 'TITAN.NS', 'MARUTI.NS', 'SUNPHARMA.NS', 'WIPRO.NS', 'ULTRACEMCO.NS',\n",
        "   'SBIN.NS', 'M&M.NS', 'ASIANPAINT.NS',  'BAJAJ-AUTO.NS', 'HCLTECH.NS',\n",
        "   'TATAMOTORS.NS', 'POWERGRID.NS', 'INDUSINDBK.NS', 'GRASIM.NS', 'BRITANNIA.NS',\n",
        "   'JSWSTEEL.NS', 'TECHM.NS', 'DIVISLAB.NS', 'HDFCLIFE.NS', 'UPL.NS', 'COALINDIA.NS',\n",
        "   'SHREECEM.NS', 'ADANIPORTS.NS', 'CIPLA.NS', 'ONGC.NS', 'DRREDDY.NS', 'HEROMOTOCO.NS',\n",
        "   'EICHERMOT.NS', 'ICICIGI.NS', 'TATACONSUM.NS', 'SBILIFE.NS','INDIAMART.NS',\n",
        "   'DABUR.NS', 'NESTLEIND.NS', 'TATAPOWER.NS', 'HAVELLS.NS', 'BIOCON.NS',\n",
        "]\n",
        "def fetch_data(tickers, start_date, end_date):\n",
        "   data = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
        "   data = data.dropna()\n",
        "   return data\n",
        "\n",
        "\n",
        "start_date = '2021-01-01'\n",
        "end_date = '2024-01-01'\n",
        "\n",
        "\n",
        "data = fetch_data(nifty_50_tickers, start_date, end_date)\n",
        "\n",
        "\n",
        "returns = data.pct_change().dropna()\n",
        "mean_returns = returns.mean()\n",
        "cov_matrix = returns.cov()\n",
        "\n",
        "\n",
        "# Step 4: Mean-Variance Optimization (Minimize Risk)\n",
        "def portfolio_performance(weights, mean_returns, cov_matrix):\n",
        "   port_return = np.sum(weights * mean_returns)\n",
        "   port_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
        "   return port_return, port_volatility\n",
        "\n",
        "\n",
        "def min_variance(weights, mean_returns, cov_matrix):\n",
        "   return portfolio_performance(weights, mean_returns, cov_matrix)[1]\n",
        "\n",
        "\n",
        "constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
        "bounds = tuple((0, 1) for _ in range(len(nifty_50_tickers)))\n",
        "\n",
        "\n",
        "initial_guess = np.ones(len(nifty_50_tickers)) / len(nifty_50_tickers)\n",
        "result = minimize(min_variance, initial_guess, args=(mean_returns, cov_matrix), method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "optimal_weights = result.x\n",
        "stock_weights = list(zip(nifty_50_tickers, optimal_weights))\n",
        "stock_weights.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "\n",
        "top_5_stocks = stock_weights[:5]\n",
        "\n",
        "\n",
        "# Print the top 5 stocks and their weights\n",
        "print(\"Top 5 Stocks Based on Risk-Return Optimization:\")\n",
        "for ticker, weight in top_5_stocks:\n",
        "   print(f\"{ticker}: {weight:.4f}\")\n",
        "\n",
        "\n",
        "tickers = [ticker for ticker, _ in top_5_stocks]\n",
        "\n",
        "\n",
        "start_date_train = '2021-01-01'\n",
        "end_date_train = '2024-01-01'\n",
        "start_date_test = '2024-01-01'\n",
        "end_date_test = '2025-01-01'\n",
        "\n",
        "\n",
        "train_data = fetch_data(tickers, start_date_train, end_date_train)\n",
        "test_data = fetch_data(tickers, start_date_test, end_date_test)\n",
        "\n",
        "\n",
        "# Check for missing data\n",
        "print(\"NaN values in train_data:\", train_data.isnull().sum())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFbbCmT4sXHI"
      },
      "source": [
        "# Using Bayesian Inferences to decide on weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0Ly-EPVCtot"
      },
      "outputs": [],
      "source": [
        "def bayesian_mean_variance_optimization(data, sentiment_values):\n",
        "    returns = data.pct_change().dropna()\n",
        "    mu = np.array(returns.mean()) * 100  # Mean returns (annualized)\n",
        "    sigma = np.array(returns.cov())  # Covariance matrix\n",
        "    mu_adjusted = mu * (1 + np.array(sentiment_values))  # Scale each stock's mean return by sentiment\n",
        "\n",
        "    risk_aversion_factor = 1 + 0.5 * np.array(sentiment_values)\n",
        "    sigma_adjusted = sigma * risk_aversion_factor[:, None]\n",
        "    sigma_adjusted += np.eye(len(mu)) * 1e-4\n",
        "    with pm.Model() as model:\n",
        "        prior_mu = pm.Normal('mu', mu=0, sigma=1, shape=data.shape[1]) #prior belief on how the stock returns behave over time.\n",
        "        prior_L = pm.LKJCholeskyCov('L', n=data.shape[1], eta=1, sd_dist=pm.HalfCauchy.dist(beta=2)) # prior belief on how the stocks correlate with each other.\n",
        "\n",
        "\n",
        "        prior_L_matrix = prior_L[0] if isinstance(prior_L, tuple) else prior_L\n",
        "        #prior_sigma = pm.Deterministic('sigma', prior_L_matrix @ prior_L_matrix.T)\n",
        "        prior_sigma = pm.Deterministic('sigma', prior_L_matrix @ prior_L_matrix.T + sigma_adjusted)\n",
        "\n",
        "        obs = pm.MvNormal('obs', mu=prior_mu, cov=prior_sigma, observed=data) #likelihood: linking actual stock data to prior beliefs: we say that there is a multivariate normal distribution between them.\n",
        "        approx = pm.fit(method=\"advi\", n=5000,progressbar=False) #using a shorter method like  advi instead of monte carlo simulation.\n",
        "        trace = approx.sample(500)\n",
        "\n",
        "    mu_posterior = trace.posterior['mu'].mean(dim=(\"chain\", \"draw\")).values\n",
        "    sigma_posterior = np.mean(trace.posterior['sigma'].values, axis=(0, 1))\n",
        "    def objective(weights):\n",
        "        return -np.dot(weights, mu_posterior) + 0.5 * np.dot(weights.T, np.dot(sigma_posterior, weights))\n",
        "\n",
        "    constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
        "    bounds = tuple((0, 1) for _ in range(len(mu)))\n",
        "\n",
        "    initial_guess = np.ones(len(mu)) / len(mu)\n",
        "\n",
        "    result = minimize(objective, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "\n",
        "    return result.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NlwyodXsjBI"
      },
      "source": [
        "# Taking input on user's view on the risk he is willing to take on the stock based on his inferences. -1 means he is willing to take the least risk, 1 implying that user wants to apply maximum risk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENc9aB_BCt3S",
        "outputId": "e971115c-ec2c-49e3-b0ba-47fb3b24c66c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide sentiment for each stock in the portfolio (use values between -1 and 1, 1 for high risk and -1 for low risk):\n",
            "Sentiment for RELIANCE.NS (between -1 and 1): 0.8\n",
            "Sentiment for TCS.NS (between -1 and 1): 0.8\n",
            "Sentiment for HDFCBANK.NS (between -1 and 1): 0.6\n",
            "Sentiment for INFY.NS (between -1 and 1): -0.4\n",
            "Sentiment for ICICIBANK.NS (between -1 and 1): 0.6\n"
          ]
        }
      ],
      "source": [
        "def get_user_sentiment():\n",
        "    print(\"Please provide sentiment for each stock in the portfolio (use values between -1 and 1, 1 for high risk and -1 for low risk):\")\n",
        "    sentiment = {}\n",
        "    for ticker in tickers:\n",
        "        sentiment[ticker] = float(input(f\"Sentiment for {ticker} (between -1 and 1): \"))\n",
        "    return list(sentiment.values())\n",
        "\n",
        "sentiment_values = get_user_sentiment()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdajczxStLX6"
      },
      "source": [
        "# We find out the initial weights(for the initial investment). We use data from 2021-2024 to track the past perfomances and define the prior in our bayesian model, and then along with user sentiment arrive at the value of the stock weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIPjLMqFCuDe",
        "outputId": "8fb604b5-429d-41b4-c033-a9765b2c4834"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimized Portfolio Weights: [0.28695135 0.2457594  0.19352074 0.20633726 0.06743125]\n"
          ]
        }
      ],
      "source": [
        "initial_weights = bayesian_mean_variance_optimization(train_data, sentiment_values)\n",
        "print(\"Optimized Portfolio Weights:\", initial_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHCEtltTCuVx"
      },
      "outputs": [],
      "source": [
        "def backtest(test_data, initial_weights, sentiment_values, initial_amount=100000):\n",
        "    weights = initial_weights\n",
        "    portfolio_value = initial_amount\n",
        "    allocation = portfolio_value * weights\n",
        "    initial_prices = test_data.iloc[0].values\n",
        "    shares = allocation / initial_prices\n",
        "\n",
        "    prev_month = test_data.index[0].month\n",
        "\n",
        "    for i in range(1, len(test_data)):\n",
        "        current_prices = test_data.iloc[i].values\n",
        "        portfolio_value = np.sum(shares * current_prices)\n",
        "        new_allocation = portfolio_value * weights\n",
        "\n",
        "        current_month = test_data.index[i].month\n",
        "\n",
        "        # Rebalance every 2 months\n",
        "        if current_month != prev_month and (current_month - prev_month) % 2 == 0:\n",
        "            print(f\"Rebalancing on {test_data.index[i]}\")\n",
        "\n",
        "            # Re-optimize with user sentiment adjustment (no need to ask for sentiment again)\n",
        "            weights = bayesian_mean_variance_optimization(test_data.iloc[:i], sentiment_values)\n",
        "\n",
        "            # Recalculate portfolio allocation based on new weights\n",
        "            new_allocation = portfolio_value * weights\n",
        "            shares = new_allocation / current_prices\n",
        "            prev_month = current_month\n",
        "\n",
        "    return portfolio_value, weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiQbbY1PtuBV"
      },
      "source": [
        "# We are rebalancing our weights every 2 months. The readjusted weights are then used for the next 2 month period."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnRiBDJ8DNoi",
        "outputId": "168d3da2-93ed-4c6f-f50b-aaf0a18a0ea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rebalancing on 2024-03-01 00:00:00\n",
            "Rebalancing on 2024-05-02 00:00:00\n",
            "Rebalancing on 2024-07-01 00:00:00\n",
            "Rebalancing on 2024-09-02 00:00:00\n",
            "Rebalancing on 2024-11-01 00:00:00\n"
          ]
        }
      ],
      "source": [
        "final_portfolio_value, final_weights = backtest(test_data, initial_weights, sentiment_values)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzXVjG7MuSYI"
      },
      "source": [
        "# Displaying final portfolio weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DSzXsG3sr_Ag",
        "outputId": "167b4565-1498-4b6c-9910-0595567c2678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Portfolio Weights:\n",
            "RELIANCE.NS: 0.2704\n",
            "TCS.NS: 0.2915\n",
            "HDFCBANK.NS: 0.1963\n",
            "INFY.NS: 0.1802\n",
            "ICICIBANK.NS: 0.0616\n"
          ]
        }
      ],
      "source": [
        "# Output final results\n",
        "\n",
        "print(\"Final Portfolio Weights:\")\n",
        "for ticker, weight in zip(tickers, final_weights):\n",
        "    print(f\"{ticker}: {weight:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44OKrR5suZ7f"
      },
      "source": [
        "# Displaying net profit at the end of one year, Sharpe ratio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fciB4GNpuO_K",
        "outputId": "70349657-815f-432c-f1d6-ae39871c148b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Portfolio Value: 116712.95935033045\n",
            "Net Profit: 16712.95935033045\n",
            "Profit % : 16.71295935033045\n"
          ]
        }
      ],
      "source": [
        "print(\"Final Portfolio Value:\", final_portfolio_value)\n",
        "print(\"Net Profit:\", final_portfolio_value - 100000)\n",
        "print(\"Profit % :\", (final_portfolio_value - 100000) / 100000 * 100)  # Percentage profit"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
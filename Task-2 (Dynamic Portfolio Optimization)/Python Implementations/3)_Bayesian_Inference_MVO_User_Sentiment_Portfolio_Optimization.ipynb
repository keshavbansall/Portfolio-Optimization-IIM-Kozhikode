{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pymc as pm\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "nifty_50_tickers = [\n",
        "    'RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ICICIBANK.NS', 'HUL.NS',\n",
        "    'HDFC.NS', 'KOTAKBANK.NS', 'BHARTIARTL.NS', 'AXISBANK.NS', 'ITC.NS', 'LT.NS',\n",
        "    'NTPC.NS', 'TITAN.NS', 'MARUTI.NS', 'SUNPHARMA.NS', 'WIPRO.NS', 'ULTRACEMCO.NS',\n",
        "    'SBIN.NS', 'M&M.NS', 'ASIANPAINT.NS', 'BAJAJ-FINANCE.NS', 'BAJAJ-AUTO.NS', 'HCLTECH.NS',\n",
        "    'TATAMOTORS.NS', 'POWERGRID.NS', 'INDUSINDBK.NS', 'GRASIM.NS', 'BRITANNIA.NS',\n",
        "    'JSWSTEEL.NS', 'TECHM.NS', 'DIVISLAB.NS', 'HDFCLIFE.NS', 'UPL.NS', 'COALINDIA.NS',\n",
        "    'SHREECEM.NS', 'ADANIPORTS.NS', 'CIPLA.NS', 'ONGC.NS', 'DRREDDY.NS', 'HEROMOTOCO.NS',\n",
        "    'EICHERMOT.NS', 'ICICIGI.NS', 'TATACONSUM.NS', 'SBILIFE.NS', 'MCDOWELL-N.NS', 'INDIAMART.NS',\n",
        "    'DABUR.NS', 'NESTLEIND.NS', 'TATAPOWER.NS', 'HAVELLS.NS', 'BIOCON.NS', 'TATAMETALI.NS'\n",
        "]\n",
        "def fetch_data(tickers, start_date, end_date):\n",
        "    data = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
        "    data = data.dropna()\n",
        "    return data\n",
        "\n",
        "start_date = '2021-01-01'\n",
        "end_date = '2024-01-01'\n",
        "\n",
        "data = fetch_data(nifty_50_tickers, start_date, end_date)\n",
        "\n",
        "returns = data.pct_change().dropna()\n",
        "mean_returns = returns.mean()\n",
        "cov_matrix = returns.cov()\n",
        "\n",
        "# Step 4: Mean-Variance Optimization (Minimize Risk)\n",
        "def portfolio_performance(weights, mean_returns, cov_matrix):\n",
        "    port_return = np.sum(weights * mean_returns)\n",
        "    port_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
        "    return port_return, port_volatility\n",
        "\n",
        "def min_variance(weights, mean_returns, cov_matrix):\n",
        "    return portfolio_performance(weights, mean_returns, cov_matrix)[1]\n",
        "\n",
        "constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
        "bounds = tuple((0, 1) for _ in range(len(nifty_50_tickers)))\n",
        "\n",
        "initial_guess = np.ones(len(nifty_50_tickers)) / len(nifty_50_tickers)\n",
        "result = minimize(min_variance, initial_guess, args=(mean_returns, cov_matrix), method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "optimal_weights = result.x\n",
        "stock_weights = list(zip(nifty_50_tickers, optimal_weights))\n",
        "stock_weights.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "top_5_stocks = stock_weights[:5]\n",
        "\n",
        "# Print the top 5 stocks and their weights\n",
        "print(\"Top 5 Stocks Based on Risk-Return Optimization:\")\n",
        "for ticker, weight in top_5_stocks:\n",
        "    print(f\"{ticker}: {weight:.4f}\")\n",
        "\n",
        "tickers = [ticker for ticker, _ in top_5_stocks]\n",
        "\n",
        "start_date_train = '2021-01-01'\n",
        "end_date_train = '2024-01-01'\n",
        "start_date_test = '2024-01-01'\n",
        "end_date_test = '2025-01-01'\n",
        "\n",
        "train_data = fetch_data(tickers, start_date_train, end_date_train)\n",
        "test_data = fetch_data(tickers, start_date_test, end_date_test)\n",
        "\n",
        "# Check for missing data\n",
        "print(\"NaN values in train_data:\", train_data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmEH098mDZJU",
        "outputId": "af3be921-a0db-46e1-938c-af1b34fbcdde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  53 of 53 completed\n",
            "ERROR:yfinance:\n",
            "5 Failed downloads:\n",
            "ERROR:yfinance:['HDFC.NS', 'MCDOWELL-N.NS', 'HUL.NS', 'BAJAJ-FINANCE.NS']: YFTzMissingError('$%ticker%: possibly delisted; no timezone found')\n",
            "ERROR:yfinance:['TATAMETALI.NS']: YFPricesMissingError('$%ticker%: possibly delisted; no price data found  (1d 2021-01-01 -> 2024-01-01)')\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:520: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
            "  ret = um.true_divide(\n",
            "/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py:11211: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  base_cov = np.cov(mat.T, ddof=ddof)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n",
            "[*********************100%***********************]  5 of 5 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Stocks Based on Risk-Return Optimization:\n",
            "RELIANCE.NS: 0.0189\n",
            "TCS.NS: 0.0189\n",
            "HDFCBANK.NS: 0.0189\n",
            "INFY.NS: 0.0189\n",
            "ICICIBANK.NS: 0.0189\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NaN values in train_data: Ticker\n",
            "HDFCBANK.NS     0\n",
            "ICICIBANK.NS    0\n",
            "INFY.NS         0\n",
            "RELIANCE.NS     0\n",
            "TCS.NS          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bayesian_mean_variance_optimization(data, sentiment_values):\n",
        "    returns = data.pct_change().dropna()\n",
        "    mu = np.array(returns.mean()) * 100  # Mean returns (annualized)\n",
        "    sigma = np.array(returns.cov())  # Covariance matrix\n",
        "    mu_adjusted = mu * (1 + np.array(sentiment_values))  # Scale each stock's mean return by sentiment\n",
        "\n",
        "    risk_aversion_factor = 1 + 0.5 * np.array(sentiment_values)\n",
        "    sigma_adjusted = sigma * risk_aversion_factor[:, None]\n",
        "    sigma_adjusted += np.eye(len(mu)) * 1e-4\n",
        "    with pm.Model() as model:\n",
        "        prior_mu = pm.Normal('mu', mu=0, sigma=1, shape=data.shape[1])\n",
        "        prior_L = pm.LKJCholeskyCov('L', n=data.shape[1], eta=1, sd_dist=pm.HalfCauchy.dist(beta=2))\n",
        "\n",
        "\n",
        "        prior_L_matrix = prior_L[0] if isinstance(prior_L, tuple) else prior_L\n",
        "        prior_sigma = pm.Deterministic('sigma', prior_L_matrix @ prior_L_matrix.T)\n",
        "        obs = pm.MvNormal('obs', mu=prior_mu, cov=prior_sigma, observed=data)\n",
        "        approx = pm.fit(method=\"advi\", n=5000,progressbar=False)\n",
        "        trace = approx.sample(500)\n",
        "\n",
        "    mu_posterior = trace.posterior['mu'].mean(dim=(\"chain\", \"draw\")).values\n",
        "    sigma_posterior = np.mean(trace.posterior['sigma'].values, axis=(0, 1))\n",
        "    def objective(weights):\n",
        "        return -np.dot(weights, mu_posterior) + 0.5 * np.dot(weights.T, np.dot(sigma_posterior, weights))\n",
        "\n",
        "    constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
        "    bounds = tuple((0, 1) for _ in range(len(mu)))\n",
        "\n",
        "    initial_guess = np.ones(len(mu)) / len(mu)\n",
        "\n",
        "    result = minimize(objective, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints)\n",
        "\n",
        "    return result.x"
      ],
      "metadata": {
        "id": "a0Ly-EPVCtot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_user_sentiment():\n",
        "    print(\"Please provide sentiment for each stock in the portfolio (use values between -1 and 1, 1 for very bullish and -1 for very bearish):\")\n",
        "    sentiment = {}\n",
        "    for ticker in tickers:\n",
        "        sentiment[ticker] = float(input(f\"Sentiment for {ticker} (between -1 and 1): \"))\n",
        "    return list(sentiment.values())\n",
        "\n",
        "sentiment_values = get_user_sentiment()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENc9aB_BCt3S",
        "outputId": "c57c35cd-26c0-4840-99d3-2561ad1ac252"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide sentiment for each stock in the portfolio (use values between -1 and 1, 1 for very bullish and -1 for very bearish):\n",
            "Sentiment for RELIANCE.NS (between -1 and 1): 0.7\n",
            "Sentiment for TCS.NS (between -1 and 1): 0.8\n",
            "Sentiment for HDFCBANK.NS (between -1 and 1): 0.9\n",
            "Sentiment for INFY.NS (between -1 and 1): 0.9\n",
            "Sentiment for ICICIBANK.NS (between -1 and 1): 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "initial_weights = bayesian_mean_variance_optimization(train_data, sentiment_values)\n",
        "print(\"Optimized Portfolio Weights:\", initial_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIPjLMqFCuDe",
        "outputId": "3578d9e5-960c-4eb2-a936-ad7dc7ec863d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Portfolio Weights: [0.26477517 0.28324697 0.18624031 0.19755817 0.06817938]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backtest(test_data, initial_weights, sentiment_values, initial_amount=100000):\n",
        "    weights = initial_weights\n",
        "    portfolio_value = initial_amount\n",
        "    allocation = portfolio_value * weights\n",
        "    initial_prices = test_data.iloc[0].values\n",
        "    shares = allocation / initial_prices\n",
        "\n",
        "    prev_month = test_data.index[0].month\n",
        "\n",
        "    for i in range(1, len(test_data)):\n",
        "        current_prices = test_data.iloc[i].values\n",
        "        portfolio_value = np.sum(shares * current_prices)\n",
        "        new_allocation = portfolio_value * weights\n",
        "\n",
        "        current_month = test_data.index[i].month\n",
        "\n",
        "        # Rebalance every 2 months\n",
        "        if current_month != prev_month and (current_month - prev_month) % 2 == 0:\n",
        "            print(f\"Rebalancing on {test_data.index[i]}\")\n",
        "\n",
        "            # Re-optimize with user sentiment adjustment (no need to ask for sentiment again)\n",
        "            weights = bayesian_mean_variance_optimization(test_data.iloc[:i], sentiment_values)\n",
        "\n",
        "            # Recalculate portfolio allocation based on new weights\n",
        "            new_allocation = portfolio_value * weights\n",
        "            shares = new_allocation / current_prices\n",
        "            prev_month = current_month\n",
        "\n",
        "    return portfolio_value, weights\n"
      ],
      "metadata": {
        "id": "LHCEtltTCuVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_portfolio_value, final_weights = backtest(test_data, initial_weights, sentiment_values)\n",
        "\n",
        "# Output final results\n",
        "print(\"Final Portfolio Value:\", final_portfolio_value)\n",
        "print(\"Net Profit:\", final_portfolio_value - 100000)\n",
        "print(\"Profit % :\", (final_portfolio_value - 100000) / 100000 * 100)  # Percentage profit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnRiBDJ8DNoi",
        "outputId": "9e009525-c087-454c-f0cd-bcaaa32620e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rebalancing on 2024-03-01 00:00:00\n",
            "Rebalancing on 2024-05-02 00:00:00\n",
            "Rebalancing on 2024-07-01 00:00:00\n",
            "Rebalancing on 2024-09-02 00:00:00\n",
            "Rebalancing on 2024-11-01 00:00:00\n",
            "Final Portfolio Value: 117615.0643496916\n",
            "Net Profit: 17615.064349691602\n",
            "Profit % : 17.615064349691604\n"
          ]
        }
      ]
    }
  ]
}